{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference Notebook\n",
    "\n",
    "This notebook acts as the backend server for the anvil web application. This notebook contains functions and utilities to make predictions and perform inference on real world data\n",
    "\n",
    "### Usage\n",
    "\n",
    "1. Run all the cells in this notebook\n",
    "2. The Web Application can be accessed here at https://apprentice.anvil.app/. The instructions to use the app can be found there itself after you visit the link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import numpy as np\n",
    "\n",
    "import datetime\n",
    "import os\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Dense, concatenate, Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to wss://anvil.works/uplink\n",
      "Anvil websocket open\n",
      "Authenticated OK\n"
     ]
    }
   ],
   "source": [
    "# Connect frontend to this notebook\n",
    "import anvil.server\n",
    "anvil.server.connect(\"KJNUXRG2JCYNR7YAK64H44KI-K3PCJOKW75T5L44P\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    \"\"\"Returns the model\"\"\"\n",
    "    input_1 = Input(shape=(512,))\n",
    "    dense_1 = Dense(256, activation='relu')(input_1)\n",
    "\n",
    "    input_2 = Input(shape=(512,))\n",
    "    dense_2 = Dense(256, activation='relu')(input_2)\n",
    "\n",
    "    concat = concatenate([dense_1, dense_2])\n",
    "    x = Dense(256, activation='relu')(concat)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    x = Dense(64, activation='relu')(x)\n",
    "    outputs = Dense(1, activation='sigmoid')(x)\n",
    "    \n",
    "    model = keras.Model(inputs=[input_1, input_2], outputs=outputs, name='SemanticNet')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(text_1, text_2):\n",
    "    \"\"\"Returns the binary prediction or two strings of texts\n",
    "    Args:\n",
    "        text_1 (str): text A\n",
    "        text_2 (str): text B\n",
    "        \n",
    "    Returns:\n",
    "        pred (float): prediction value in range 0-1\n",
    "    \"\"\"\n",
    "    # preprocess the text to embeddings using USE\n",
    "    embeddings = encoder([text_1, text_2])\n",
    "    embeddings = np.expand_dims(embeddings, axis=0)\n",
    "    # make predictions\n",
    "    pred = model.predict([embeddings[:,0], embeddings[:,1]])\n",
    "    return float(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the model\n",
    "model = create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the weights of the trained models\n",
    "model.load_weights('model/sem_net_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from Local Directory...\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "# load the Universal Sentence Encoder from tensorflow hub\n",
    "if os.path.isdir('4'):\n",
    "    print('Loading model from Local Directory...')\n",
    "    encoder = hub.load('4')\n",
    "    print('Done')\n",
    "else:\n",
    "    print('Downloading model...')\n",
    "    encoder = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\n",
    "    print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\bhave\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check a student's answer given a solution by the teacher\n",
    "@anvil.server.callable\n",
    "def check(answer, solution):\n",
    "    \"\"\"Returns the number of facts correct out of total facts i.e. score.\n",
    "    Args:\n",
    "        answer (str): the student's answer\n",
    "        solution (str): the teacher's solution\n",
    "        \n",
    "    Returns:\n",
    "        (score, total_facts, message) (tuple)\n",
    "    \"\"\"\n",
    "    # split into sentences\n",
    "    ans = nltk.tokenize.sent_tokenize(answer)\n",
    "    sol = nltk.tokenize.sent_tokenize(solution)\n",
    "    \n",
    "    score = 0\n",
    "    # check answer with every fact in the solution\n",
    "    for i in range(len(ans)):\n",
    "        for j in range(len(sol)):\n",
    "            prob = predict(ans[i], sol[j])\n",
    "            pred = int(np.round(prob))\n",
    "            score += pred\n",
    "            \n",
    "    if score > len(sol):\n",
    "        score = len(sol)\n",
    "    # print the scores\n",
    "    msg = 'Result: {} of {} facts correct'.format(score, len(sol))\n",
    "    print(msg)\n",
    "    return (score, len(sol), msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample pairs of text\n",
    "solution = \"\"\"The woman cried out for help because a snake had trespassed into her house.\n",
    "The old woman was happy because she got a precious pearl necklace.\"\"\"\n",
    "answer = \"\"\"The lady was happy as she got a necklace\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: 1 of 2 facts correct\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1, 2, 'Result: 1 of 2 facts correct')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: 0 of 2 facts correct\n"
     ]
    }
   ],
   "source": [
    "# check the answer against the solution\n",
    "check(answer, solution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
